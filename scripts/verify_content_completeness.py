#!/usr/bin/env python3
"""
æ–‡æ¡£å†…å®¹å®Œæ•´æ€§éªŒè¯è„šæœ¬

æ­¤è„šæœ¬å¯¹æ¯”æ–°æ—§æ–‡æ¡£ï¼Œç¡®è®¤æ‰€æœ‰é‡è¦ä¿¡æ¯å·²ä¿ç•™ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å†…å®¹ä¸¢å¤±æˆ–é—æ¼ã€‚
"""

import os
import re
from pathlib import Path
from typing import Dict, List, Set, Tuple
from dataclasses import dataclass, field


@dataclass
class DocumentMetrics:
    """æ–‡æ¡£åº¦é‡æŒ‡æ ‡"""
    filename: str
    word_count: int
    code_blocks: int
    headings: int
    links: int
    lists: int
    tables: int
    key_terms: Set[str] = field(default_factory=set)
    code_examples: List[str] = field(default_factory=list)


@dataclass
class ContentComparison:
    """å†…å®¹å¯¹æ¯”ç»“æœ"""
    old_doc: str
    new_doc: str
    old_metrics: DocumentMetrics
    new_metrics: DocumentMetrics
    missing_terms: Set[str] = field(default_factory=set)
    missing_code: List[str] = field(default_factory=list)
    content_preserved: bool = True
    notes: List[str] = field(default_factory=list)


class ContentVerifier:
    """æ–‡æ¡£å†…å®¹éªŒè¯å™¨"""
    
    def __init__(self, backup_dir: str, current_dir: str):
        self.backup_dir = Path(backup_dir)
        self.current_dir = Path(current_dir)
        self.comparisons: List[ContentComparison] = []
        
        # æ–‡æ¡£æ˜ å°„ï¼šæ—§æ–‡æ¡£ -> æ–°æ–‡æ¡£
        self.doc_mapping = {
            # ç”¨æˆ·æŒ‡å—ç±»
            "ui-system-guide.md": "user-guide.md",
            "progress-manager-guide.md": "user-guide.md",
            "startup-experience-guide.md": "user-guide.md",
            "security-checker-guide.md": "user-guide.md",
            "template-quick-start.md": "template-guide.md",
            "custom-template-guide.md": "template-guide.md",
            "template-cli-reference.md": ["template-guide.md", "cli-reference.md"],
            "template-quick-reference.md": "template-guide.md",
            "ui-configuration-guide.md": "user-guide.md",
            
            # å¼€å‘è€…æ–‡æ¡£ç±»
            "config-module-implementation.md": ["architecture.md", "config-reference.md"],
            "context-module-implementation.md": "architecture.md",
            "storage-engine-implementation.md": "architecture.md",
            "security-engine-implementation.md": "architecture.md",
            "main-controller-implementation.md": "architecture.md",
            "documentation-guide.md": "developer-guide.md",
            
            # éƒ¨ç½²è¿ç»´ç±»
            "docker-deployment.md": "deployment-guide.md",
            "ci-cd-setup.md": "deployment-guide.md",
            "cicd-and-license-guide.md": "deployment-guide.md",
            "release-process.md": "deployment-guide.md",
            "deployment-checklist.md": "deployment-guide.md",
            "ollama-setup.md": "deployment-guide.md",
            
            # ä¿ç•™çš„æ–‡æ¡£
            "architecture.md": "architecture.md",
            "developer-guide.md": "developer-guide.md",
            "README.md": "README.md",
            "theme-customization-guide.md": "theme-customization-guide.md",
        }
    
    def extract_metrics(self, content: str, filename: str) -> DocumentMetrics:
        """æå–æ–‡æ¡£åº¦é‡æŒ‡æ ‡"""
        # ç»Ÿè®¡å­—æ•°ï¼ˆä¸­è‹±æ–‡ï¼‰
        chinese_chars = len(re.findall(r'[\u4e00-\u9fff]', content))
        english_words = len(re.findall(r'\b[a-zA-Z]+\b', content))
        word_count = chinese_chars + english_words
        
        # ç»Ÿè®¡ä»£ç å—
        code_blocks = len(re.findall(r'```[\s\S]*?```', content))
        code_examples = re.findall(r'```([\s\S]*?)```', content)
        
        # ç»Ÿè®¡æ ‡é¢˜
        headings = len(re.findall(r'^#{1,6}\s+.+$', content, re.MULTILINE))
        
        # ç»Ÿè®¡é“¾æ¥
        links = len(re.findall(r'\[.+?\]\(.+?\)', content))
        
        # ç»Ÿè®¡åˆ—è¡¨é¡¹
        lists = len(re.findall(r'^\s*[-*+]\s+', content, re.MULTILINE))
        lists += len(re.findall(r'^\s*\d+\.\s+', content, re.MULTILINE))
        
        # ç»Ÿè®¡è¡¨æ ¼
        tables = len(re.findall(r'\|.+\|', content))
        
        # æå–å…³é”®æœ¯è¯­ï¼ˆæ ‡é¢˜ä¸­çš„è¯æ±‡ï¼‰
        key_terms = set()
        for heading in re.findall(r'^#{1,6}\s+(.+)$', content, re.MULTILINE):
            # æ¸…ç†æ ‡é¢˜æ–‡æœ¬
            heading = re.sub(r'[#\[\](){}]', '', heading).strip()
            if heading:
                key_terms.add(heading.lower())
        
        return DocumentMetrics(
            filename=filename,
            word_count=word_count,
            code_blocks=code_blocks,
            headings=headings,
            links=links,
            lists=lists,
            tables=tables,
            key_terms=key_terms,
            code_examples=code_examples
        )
    
    def read_document(self, path: Path) -> str:
        """è¯»å–æ–‡æ¡£å†…å®¹"""
        try:
            with open(path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            print(f"âš ï¸  æ— æ³•è¯»å–æ–‡ä»¶ {path}: {e}")
            return ""
    
    def compare_documents(self, old_doc: str, new_docs: List[str]) -> ContentComparison:
        """å¯¹æ¯”æ—§æ–‡æ¡£å’Œæ–°æ–‡æ¡£"""
        old_path = self.backup_dir / old_doc
        old_content = self.read_document(old_path)
        old_metrics = self.extract_metrics(old_content, old_doc)
        
        # è¯»å–æ‰€æœ‰æ–°æ–‡æ¡£å†…å®¹
        new_content_combined = ""
        new_metrics_list = []
        
        for new_doc in new_docs:
            new_path = self.current_dir / new_doc
            if new_path.exists():
                new_content = self.read_document(new_path)
                new_content_combined += "\n" + new_content
                new_metrics_list.append(self.extract_metrics(new_content, new_doc))
        
        # åˆå¹¶æ–°æ–‡æ¡£çš„åº¦é‡æŒ‡æ ‡
        if new_metrics_list:
            new_metrics = DocumentMetrics(
                filename=" + ".join(new_docs),
                word_count=sum(m.word_count for m in new_metrics_list),
                code_blocks=sum(m.code_blocks for m in new_metrics_list),
                headings=sum(m.headings for m in new_metrics_list),
                links=sum(m.links for m in new_metrics_list),
                lists=sum(m.lists for m in new_metrics_list),
                tables=sum(m.tables for m in new_metrics_list),
                key_terms=set().union(*[m.key_terms for m in new_metrics_list]),
                code_examples=[ex for m in new_metrics_list for ex in m.code_examples]
            )
        else:
            new_metrics = DocumentMetrics(filename="æœªæ‰¾åˆ°", word_count=0, code_blocks=0,
                                         headings=0, links=0, lists=0, tables=0)
        
        # æ£€æŸ¥ç¼ºå¤±çš„å…³é”®æœ¯è¯­
        missing_terms = old_metrics.key_terms - new_metrics.key_terms
        
        # æ£€æŸ¥ç¼ºå¤±çš„ä»£ç ç¤ºä¾‹ï¼ˆç®€åŒ–æ¯”è¾ƒï¼‰
        missing_code = []
        for old_code in old_metrics.code_examples:
            old_code_clean = re.sub(r'\s+', '', old_code.strip())
            if len(old_code_clean) > 50:  # åªæ£€æŸ¥è¾ƒé•¿çš„ä»£ç ç¤ºä¾‹
                found = False
                for new_code in new_metrics.code_examples:
                    new_code_clean = re.sub(r'\s+', '', new_code.strip())
                    if old_code_clean in new_code_clean or new_code_clean in old_code_clean:
                        found = True
                        break
                if not found:
                    missing_code.append(old_code[:100] + "..." if len(old_code) > 100 else old_code)
        
        # åˆ¤æ–­å†…å®¹æ˜¯å¦ä¿ç•™
        content_preserved = True
        notes = []
        
        if not new_metrics_list:
            content_preserved = False
            notes.append("âš ï¸  æ–°æ–‡æ¡£ä¸å­˜åœ¨")
        elif old_metrics.word_count > 0:
            # å…è®¸ä¸€å®šçš„å†…å®¹å‡å°‘ï¼ˆç”±äºé‡å¤å†…å®¹åˆå¹¶ï¼‰
            word_ratio = new_metrics.word_count / old_metrics.word_count
            if word_ratio < 0.3:  # å¦‚æœæ–°æ–‡æ¡£å­—æ•°å°‘äºæ—§æ–‡æ¡£çš„30%
                notes.append(f"âš ï¸  å­—æ•°æ˜¾è‘—å‡å°‘: {old_metrics.word_count} -> {new_metrics.word_count} ({word_ratio:.1%})")
            
            # æ£€æŸ¥ä»£ç å—
            if old_metrics.code_blocks > 0 and new_metrics.code_blocks == 0:
                content_preserved = False
                notes.append(f"âŒ æ‰€æœ‰ä»£ç å—ä¸¢å¤±: {old_metrics.code_blocks} ä¸ª")
            elif old_metrics.code_blocks > new_metrics.code_blocks + 2:
                notes.append(f"âš ï¸  ä»£ç å—å‡å°‘: {old_metrics.code_blocks} -> {new_metrics.code_blocks}")
            
            # æ£€æŸ¥å…³é”®æœ¯è¯­
            if len(missing_terms) > len(old_metrics.key_terms) * 0.5:
                notes.append(f"âš ï¸  å¤§é‡å…³é”®æœ¯è¯­ç¼ºå¤±: {len(missing_terms)}/{len(old_metrics.key_terms)}")
        
        return ContentComparison(
            old_doc=old_doc,
            new_doc=" + ".join(new_docs),
            old_metrics=old_metrics,
            new_metrics=new_metrics,
            missing_terms=missing_terms,
            missing_code=missing_code,
            content_preserved=content_preserved,
            notes=notes
        )
    
    def verify_all(self) -> List[ContentComparison]:
        """éªŒè¯æ‰€æœ‰æ–‡æ¡£"""
        print("ğŸ” å¼€å§‹éªŒè¯æ–‡æ¡£å†…å®¹å®Œæ•´æ€§...\n")
        
        for old_doc, new_doc in self.doc_mapping.items():
            # å¤„ç†ä¸€å¯¹å¤šçš„æ˜ å°„
            new_docs = new_doc if isinstance(new_doc, list) else [new_doc]
            
            print(f"ğŸ“„ å¯¹æ¯”: {old_doc} -> {', '.join(new_docs)}")
            comparison = self.compare_documents(old_doc, new_docs)
            self.comparisons.append(comparison)
        
        return self.comparisons
    
    def generate_report(self) -> str:
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        report = []
        report.append("# æ–‡æ¡£å†…å®¹å®Œæ•´æ€§éªŒè¯æŠ¥å‘Š\n")
        report.append(f"**éªŒè¯æ—¥æœŸ**: 2025-10-17\n")
        report.append(f"**å¤‡ä»½ç›®å½•**: {self.backup_dir}\n")
        report.append(f"**å½“å‰ç›®å½•**: {self.current_dir}\n")
        report.append(f"**éªŒè¯æ–‡æ¡£æ•°**: {len(self.comparisons)}\n\n")
        
        # ç»Ÿè®¡
        total = len(self.comparisons)
        preserved = sum(1 for c in self.comparisons if c.content_preserved)
        issues = total - preserved
        
        report.append("## ğŸ“Š éªŒè¯æ‘˜è¦\n\n")
        report.append(f"- âœ… å†…å®¹å®Œæ•´ä¿ç•™: {preserved}/{total} ({preserved/total*100:.1f}%)\n")
        report.append(f"- âš ï¸  éœ€è¦å…³æ³¨: {issues}/{total}\n\n")
        
        # è¯¦ç»†å¯¹æ¯”
        report.append("## ğŸ“‹ è¯¦ç»†å¯¹æ¯”ç»“æœ\n\n")
        
        for i, comp in enumerate(self.comparisons, 1):
            status = "âœ…" if comp.content_preserved else "âš ï¸"
            report.append(f"### {i}. {status} {comp.old_doc}\n\n")
            report.append(f"**æ˜ å°„åˆ°**: {comp.new_doc}\n\n")
            
            # åº¦é‡å¯¹æ¯”è¡¨
            report.append("| æŒ‡æ ‡ | æ—§æ–‡æ¡£ | æ–°æ–‡æ¡£ | å˜åŒ– |\n")
            report.append("|------|--------|--------|------|\n")
            
            old_m = comp.old_metrics
            new_m = comp.new_metrics
            
            report.append(f"| å­—æ•° | {old_m.word_count:,} | {new_m.word_count:,} | ")
            if new_m.word_count >= old_m.word_count * 0.7:
                report.append("âœ… |\n")
            else:
                report.append(f"âš ï¸ {(new_m.word_count/old_m.word_count*100 if old_m.word_count > 0 else 0):.0f}% |\n")
            
            report.append(f"| ä»£ç å— | {old_m.code_blocks} | {new_m.code_blocks} | ")
            if new_m.code_blocks >= old_m.code_blocks * 0.8:
                report.append("âœ… |\n")
            elif old_m.code_blocks == 0:
                report.append("N/A |\n")
            else:
                report.append(f"âš ï¸ {(new_m.code_blocks/old_m.code_blocks*100):.0f}% |\n")
            
            report.append(f"| æ ‡é¢˜æ•° | {old_m.headings} | {new_m.headings} | ")
            report.append("âœ… |\n" if new_m.headings > 0 else "âš ï¸ |\n")
            
            report.append(f"| é“¾æ¥æ•° | {old_m.links} | {new_m.links} | âœ… |\n")
            report.append(f"| åˆ—è¡¨é¡¹ | {old_m.lists} | {new_m.lists} | âœ… |\n\n")
            
            # æ³¨æ„äº‹é¡¹
            if comp.notes:
                report.append("**æ³¨æ„äº‹é¡¹**:\n")
                for note in comp.notes:
                    report.append(f"- {note}\n")
                report.append("\n")
            
            # ç¼ºå¤±çš„å…³é”®æœ¯è¯­
            if comp.missing_terms and len(comp.missing_terms) <= 10:
                report.append(f"**å¯èƒ½ç¼ºå¤±çš„ä¸»é¢˜** ({len(comp.missing_terms)} ä¸ª):\n")
                for term in sorted(list(comp.missing_terms)[:10]):
                    report.append(f"- {term}\n")
                report.append("\n")
            elif len(comp.missing_terms) > 10:
                report.append(f"**å¯èƒ½ç¼ºå¤±çš„ä¸»é¢˜**: {len(comp.missing_terms)} ä¸ªï¼ˆè¾ƒå¤šï¼Œå»ºè®®äººå·¥å®¡æŸ¥ï¼‰\n\n")
            
            # ç¼ºå¤±çš„ä»£ç ç¤ºä¾‹
            if comp.missing_code:
                report.append(f"**å¯èƒ½ç¼ºå¤±çš„ä»£ç ç¤ºä¾‹** ({len(comp.missing_code)} ä¸ª):\n")
                for code in comp.missing_code[:3]:  # åªæ˜¾ç¤ºå‰3ä¸ª
                    report.append(f"```\n{code}\n```\n\n")
                if len(comp.missing_code) > 3:
                    report.append(f"...è¿˜æœ‰ {len(comp.missing_code) - 3} ä¸ªä»£ç ç¤ºä¾‹\n\n")
            
            report.append("---\n\n")
        
        # å½’æ¡£æ–‡æ¡£
        report.append("## ğŸ“¦ å½’æ¡£æ–‡æ¡£\n\n")
        report.append("ä»¥ä¸‹æ–‡æ¡£å·²å½’æ¡£åˆ° `docs/archive/`ï¼Œä¸éœ€è¦å†…å®¹è¿ç§»ï¼š\n\n")
        archived = ["cleanup-summary.md", "documentation-optimization-summary.md", 
                   "release-deployment-summary.md"]
        for doc in archived:
            report.append(f"- {doc}\n")
        report.append("\n")
        
        # ç»“è®º
        report.append("## ğŸ¯ éªŒè¯ç»“è®º\n\n")
        
        if issues == 0:
            report.append("âœ… **æ‰€æœ‰æ–‡æ¡£å†…å®¹å·²å®Œæ•´ä¿ç•™**\n\n")
            report.append("æ‰€æœ‰æ—§æ–‡æ¡£çš„é‡è¦ä¿¡æ¯éƒ½å·²æˆåŠŸè¿ç§»åˆ°æ–°æ–‡æ¡£ä¸­ã€‚\n\n")
        else:
            report.append(f"âš ï¸  **æœ‰ {issues} ä¸ªæ–‡æ¡£éœ€è¦äººå·¥å®¡æŸ¥**\n\n")
            report.append("å»ºè®®å¯¹æ ‡è®°ä¸º âš ï¸ çš„æ–‡æ¡£è¿›è¡Œäººå·¥å®¡æŸ¥ï¼Œç¡®è®¤å†…å®¹æ˜¯å¦å®Œæ•´ã€‚\n\n")
        
        report.append("### å»ºè®®è¡ŒåŠ¨\n\n")
        report.append("1. å®¡æŸ¥æ‰€æœ‰æ ‡è®°ä¸º âš ï¸ çš„æ–‡æ¡£å¯¹æ¯”\n")
        report.append("2. æ£€æŸ¥\"å¯èƒ½ç¼ºå¤±çš„ä¸»é¢˜\"æ˜¯å¦ä¸ºé‡è¦å†…å®¹\n")
        report.append("3. éªŒè¯\"å¯èƒ½ç¼ºå¤±çš„ä»£ç ç¤ºä¾‹\"æ˜¯å¦éœ€è¦è¡¥å……\n")
        report.append("4. å¯¹äºå­—æ•°æ˜¾è‘—å‡å°‘çš„æ–‡æ¡£ï¼Œç¡®è®¤æ˜¯å¦ä¸ºåˆç†çš„å»é‡\n\n")
        
        report.append("---\n\n")
        report.append("*æ­¤æŠ¥å‘Šç”±è‡ªåŠ¨åŒ–è„šæœ¬ç”Ÿæˆï¼Œå»ºè®®ç»“åˆäººå·¥å®¡æŸ¥ç¡®ä¿å†…å®¹å®Œæ•´æ€§*\n")
        
        return "".join(report)
    
    def print_summary(self):
        """æ‰“å°éªŒè¯æ‘˜è¦"""
        print("\n" + "="*70)
        print("ğŸ“Š éªŒè¯æ‘˜è¦")
        print("="*70 + "\n")
        
        total = len(self.comparisons)
        preserved = sum(1 for c in self.comparisons if c.content_preserved)
        issues = total - preserved
        
        print(f"âœ… å†…å®¹å®Œæ•´ä¿ç•™: {preserved}/{total} ({preserved/total*100:.1f}%)")
        print(f"âš ï¸  éœ€è¦å…³æ³¨: {issues}/{total}\n")
        
        if issues > 0:
            print("éœ€è¦å…³æ³¨çš„æ–‡æ¡£:")
            for comp in self.comparisons:
                if not comp.content_preserved:
                    print(f"  âš ï¸  {comp.old_doc} -> {comp.new_doc}")
                    for note in comp.notes:
                        print(f"      {note}")
        else:
            print("ğŸ‰ æ‰€æœ‰æ–‡æ¡£å†…å®¹å·²å®Œæ•´ä¿ç•™ï¼")
        
        print("\n" + "="*70)


def main():
    """ä¸»å‡½æ•°"""
    backup_dir = "docs_backup_20251017"
    current_dir = "docs"
    
    verifier = ContentVerifier(backup_dir, current_dir)
    verifier.verify_all()
    
    # ç”ŸæˆæŠ¥å‘Š
    report = verifier.generate_report()
    
    # ä¿å­˜æŠ¥å‘Š
    report_path = Path("docs/content-verification-report.md")
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nâœ… éªŒè¯æŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    # æ‰“å°æ‘˜è¦
    verifier.print_summary()


if __name__ == "__main__":
    main()
